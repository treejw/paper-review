# [MMGCN: Multi-modal Graph Convolution Network for Personalized Recommendation of Micro-video](http://staff.ustc.edu.cn/~hexn/papers/mm19-MMGCN.pdf)  `2019`

<br>

## 1. Background Knowledge
### **Multimodal**
- 인간은 살아가는 데 필요한 정보를 학습하기위해 대표적으로 5개의 감각 기관으로 부터 수집되는 데이터를 바탕 학습
- 인간의 인지적 학습법을 모방하여 다양한 형태(modality) 데이터로 학습하는 방법
- 즉, **특징 차원이 다른 데이터**를 동시에 학습하는 방법
<br>

**Multimodal learning**
- **Joint representaion**
   - 각각의 modality가 서로 같은 공간으로 합쳐져서 하나의 모델을 통과하는 방법
   - x = f(x1,x2,...)
- **Coordinated representations** 
   - 각각의 modality마다 개별 모델을 통과하는 방법  
   - x = f(x1)g(x2)


<br><br>

## 2. Introduction

<br><br>

## 3. MODEL FRAMEWORK

<br><br>

## 4. Experiments

<br><br>
